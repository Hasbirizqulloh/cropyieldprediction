# -*- coding: utf-8 -*-
"""Submission_Crop Yield Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KbHdijZxhL6RRHYjZqVkm1kQIt4yKFOV

# Proyek Submission Machine Learning Terapan: Crop Yield Prediction
- **Nama:** Moh Hasbi Rizqulloh
- **Email:** hasbirizqulloh95@gmail.com
- **ID Dicoding:** hasbirizqulloh

# **1. Import Semua Packages/Library yang Digunakan**
"""

import kagglehub
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import os
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score

"""# **2. Data Loading**"""

# Download latest version
path = kagglehub.dataset_download("mrigaankjaswal/crop-yield-prediction-dataset")

print("Path to dataset files:", path)

os.listdir(path)

df = pd.read_csv(os.path.join(path, "yield_df.csv"))
df

"""# **3. Eksploratory Data Analysis**

## Mengecek Struktur Data
"""

df.info()

df.describe()

"""Insight
- `hg/ha_yield` Nilai maksimum jauh lebih besar dari Q3 dan median → kemungkinan ada outlier di bagian atas.
- `pesticides_tonnes` Max sangat jauh dari Q3 dan mean ada indikasi kuat outlier atau bisa jadi salah input atau terkendala dengan tahun dan area negara yang menerapkan kebijakan ketat tentang pestisida.
- `avg_temp` Distribusi terlihat normal, tapi nilai minimum 1.3 °C cukup rendah untuk data rata-rata tahunan (kecuali ini dari negara seperti Greenland atau pegunungan tinggi). Perlu dicek datanya berasal dari mana (Area).

## Menangani Missing Values
"""

df.isnull().sum()

df['Unnamed: 0']

df_clean = df.drop(columns=['Unnamed: 0'])
df_clean

df_clean[df_clean['pesticides_tonnes'] == 0.04]

pestisida = (df_clean.pesticides_tonnes == 0.04).sum()
print(pestisida)

df_clean.loc[df_clean['avg_temp'] == 1.3]

df_clean.shape

"""Insight
- Tidak ada nilai kosong (NaN/null) di semua kolom.
- Terdapat kolom bernama Unnamed yang redundant, kolom ini hanya duplikasi dari index baris. Sudah seharusnya dihapus, karena tidak menambah informasi apa pun.
- Nilai minimum `pesticides_tonnes` adalah 0.04, sangat kecil dibandingkan Q1 (1702) hingga max (367,778). ini akan ditangani di outlier karena setelah di cek bukan karena kesalahan input yang menimbulkan missing values melainkan karena faktor negara dan tahun-tahun awal (1990-an) — wajar untuk masa itu (belum banyak pakai pestisida).
- `avg_temp` minimum untuk suhu rata-rata tahunan 1.3°C di Norway masih masuk akal karena negara Skandinavia yang dingin. ini akan dicek lebih lanjut pada penanganan outlier.
- Bisa langsung lanjut ke eksplorasi data, visualisasi, dan modeling tanpa
hambatan karena missing value.

## Menangangi Outlier

Boxplot untuk Mendeteksi Outlier pada Fitur
"""

sns.boxplot(x=df_clean['pesticides_tonnes'])

sns.boxplot(x=df_clean['hg/ha_yield'])

sns.boxplot(x=df_clean['avg_temp'])

"""Menghapus Outlier Menggunakan Metode IQR (Interquartile Range)"""

outlier_cols = df_clean[['pesticides_tonnes', 'avg_temp', 'hg/ha_yield']]
Q1 = outlier_cols.quantile(0.25)
Q3 = outlier_cols.quantile(0.75)
IQR = Q3 - Q1

df_clean_ou = df_clean[~((outlier_cols < (Q1 - 1.5 * IQR)) |(outlier_cols > (Q3 + 1.5 * IQR))).any(axis=1)]

df_clean_ou.shape

df_clean_ou.info()

df_clean_ou.describe()

"""Insight
- Nilai outlier sudah diatasi dengan menggunakan metode IQR, terlihat pada tabel descriptive statisticnya sudah terlihat lebih baik nilai outliernya dibanding sebelumnya.

## Univariate Analysis

### Categorical Features
"""

categorical_features = df_clean_ou.select_dtypes(include='object').columns.tolist()

categorical_features

"""##### Visualisasi Jumlah dan Persentase Kategori pada Fitur"""

feature = categorical_features[0]
count = df_clean_ou[feature].value_counts()
percent = 100 * df_clean_ou[feature].value_counts(normalize=True)
count_percent = pd.DataFrame({'count': count, 'percent': percent.round(1)})
print(count_percent)
count.sort_values().plot(kind='barh', figsize=(10, 20), title=f'Count Distribution for {feature}')

feature = categorical_features[1]
count = df_clean_ou[feature].value_counts()
percent = 100 * df_clean_ou[feature].value_counts(normalize=True)
count_percent = pd.DataFrame({'count': count, 'percent': percent.round(1)})
print(count_percent)
count.plot(kind='bar', title=f'Count Distribution for {feature}')

"""### Numerical Features

Visualisasi Distribusi Fitur dengan Histogram
"""

df_clean_ou.hist(bins=60, figsize=(20, 15))
plt.show()

"""### Multivariate Analysis

Analisis Visual Fitur Kategorikal terhadap Target (hg/ha_yield)
"""

cat_feature = df_clean_ou.select_dtypes(include='object').columns.tolist()
for feature in cat_feature:
    sns.catplot(x=feature, y='hg/ha_yield', data=df_clean_ou, kind='bar', height=4, aspect=3, palette='Set3')
    plt.xticks(rotation=90)
    plt.show()

"""Visualisasi Hubungan Antar Variabel dengan Pairplot"""

sns.pairplot(df_clean_ou)
plt.show()

"""Visualisasi Korelasi Fitur Numerik dengan Heatmap"""

numerical_features = df_clean_ou.select_dtypes(include='number').columns.tolist()
plt.figure(figsize=(10, 8))
correlation_matrix = df_clean_ou[numerical_features].corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title('Correlation Matrix for Numerical Features', size=15)

df_clean_ou.head()

"""# **4. Data Preparation**

## Encoding fitur kategori

### OneHot Encoding
"""

cat_columns = df_clean_ou.select_dtypes(include='object').columns.tolist()

df_onehot_encoded = pd.get_dummies(df, columns=cat_columns)

df_onehot_encoded

"""## Splitting Data

Menentukan Variabel Fitur dan Target
"""

X = df_onehot_encoded.drop(columns=['hg/ha_yield'])
y = df_onehot_encoded['hg/ha_yield']

"""Membagi Data Menjadi Data Latih dan Data Uji"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Ukuran data latih:", X_train.shape)
print("Ukuran label latih:", y_train.shape)
print("Ukuran data uji:", X_test.shape)
print("Ukuran label uji:", y_test.shape)

"""## Reduksi PCA dan Standarisasi

Normalisasi Data Menggunakan StandardScaler pada Data Train dan Test
"""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""Reduksi Dimensi dengan PCA (Principal Component Analysis)"""

pca = PCA(n_components=0.9)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

print("Dimensi asli:", X_train.shape[1])
print("Dimensi setelah PCA:", X_train_pca.shape[1])
print("Total variansi terjaga:", np.sum(pca.explained_variance_ratio_))

"""# 5. **Model Development**

## Linear Regression
"""

# Inisialisasi model
lr_model = LinearRegression()

# Latih model pada data training
lr_model.fit(X_train_pca, y_train)

# Prediksi pada data testing
y_pred = lr_model.predict(X_test_pca)

# Evaluasi performa model
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print("Linear Regression Performance:")
print(f"RMSE: {rmse:.2f}")
print(f"R² Score: {r2:.2f}")

"""## Random Forest Regressor"""

# Inisialisasi model
rf_model = RandomForestRegressor(n_estimators=5, random_state=42)

# Latih model pada data training
rf_model.fit(X_train_pca, y_train)

# Prediksi pada data testing
y_pred_rf = rf_model.predict(X_test_pca)

# Evaluasi performa model
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_rf = r2_score(y_test, y_pred_rf)

print("Random Forest Performance:")
print(f"RMSE: {rmse_rf:.2f}")
print(f"R² Score: {r2_rf:.2f}")

"""## Extreme Gradient Boosting"""

# Inisialisasi model
xgb_model = XGBRegressor(
    objective='reg:squarederror',
    n_estimators=100,
    learning_rate=0.1,
    max_depth=6,
    random_state=42,
    n_jobs=-1
)

# Latih model pada data training
xgb_model.fit(X_train_pca, y_train)

# Prediksi pada data testing
y_pred_xgb = xgb_model.predict(X_test_pca)

# Evaluasi performa model
rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))
r2_xgb   = r2_score(y_test, y_pred_xgb)

print("XGBoost Regression Performance:")
print(f" RMSE : {rmse_xgb:.2f}")
print(f" R²   : {r2_xgb:.2f}")

"""# **6. Evaluasi Model**

### Menghitung MSE (Mean Squared Error) untuk Data Train dan Test pada Masing-Masing Algoritma
"""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['LR','RF','Boosting'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'LR': lr_model, 'RF': rf_model, 'Boosting': xgb_model}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train_pca))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test_pca))/1e3

# Panggil mse
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""### Prediksi Menggunakan Model pada Data Uji (Test Data) untuk Evaluasi"""

prediksi = X_test_pca[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)